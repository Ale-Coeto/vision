{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"raw\"\n",
    "results_dir = \"output\"\n",
    "\n",
    "if not os.path.exists(images_dir):\n",
    "  os.makedirs(images_dir)\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "  os.makedirs(results_dir)\n",
    "\n",
    "if not os.path.exists(\"masks\"):\n",
    "  os.makedirs(\"masks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_model = \"h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sam_model ==\"h\":\n",
    "  sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "  model_type = \"vit_h\"\n",
    "else:\n",
    "  sam_checkpoint = \"sam_vit_l_0b3195.pth\"\n",
    "  model_type = \"vit_l\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [str(\"NAO\" + str(i) + \".jpeg\") for i in range(1, 38)] #37\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the pose solution from MediaPipe\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Calling the solution for image drawing from MediaPipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as pose:\n",
    "    for file in images:\n",
    "        print(file)\n",
    "        image = cv2.imread(os.path.join(images_dir, file))\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        x_min = 10000\n",
    "        x_max = 0\n",
    "        y_min = 10000\n",
    "        y_max = 0\n",
    "        margin_x = 290\n",
    "        margin_y = 240\n",
    "        if not results.pose_landmarks:\n",
    "            continue\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            x_min = min(x_min, landmark.x)\n",
    "            x_max = max(x_max, landmark.x)\n",
    "            y_min = min(y_min, landmark.y)\n",
    "            y_max = max(y_max, landmark.y)\n",
    "\n",
    "        x_min = int(x_min * image.shape[1])\n",
    "        x_max = int(x_max * image.shape[1])\n",
    "        y_min = int(y_min * image.shape[0])\n",
    "        y_max = int(y_max * image.shape[0])\n",
    "\n",
    "        x_min = max(0,x_min - margin_x)\n",
    "        y_min = max(0,y_min - margin_y)\n",
    "        x_max = min(image.shape[1],x_max + margin_x)\n",
    "        y_max = min(image.shape[0],y_max + margin_y)\n",
    "\n",
    "        bbox = np.array([x_min, y_min, x_max, y_max])\n",
    "        xywh = np.array([x_min, y_min, x_max - x_min, y_max - y_min])\n",
    "\n",
    "        predictor.set_image(image)\n",
    "\n",
    "        mask, _, _ = predictor.predict(\n",
    "          point_coords=None,\n",
    "          point_labels=None,\n",
    "          box=bbox,\n",
    "          multimask_output=False,\n",
    "        )\n",
    "\n",
    "        mask = np.array(mask)\n",
    "        mask = np.where(mask, 1, 0)\n",
    "        cv2.imwrite(os.path.join(\"masks\", file), mask[0] * 255)\n",
    "\n",
    "        mask = np.where(mask, 1, 0)\n",
    "\n",
    "        mask = mask[0] * 255\n",
    "        mask = mask.astype(np.uint8)\n",
    "        masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "\n",
    "\n",
    "        cv2.imwrite(os.path.join(results_dir, file), masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as pose:\n",
    "    for file in images:\n",
    "        print(file)\n",
    "        image = cv2.imread(os.path.join(images_dir, file))\n",
    "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        x_min = 10000\n",
    "        x_max = 0\n",
    "        y_min = 10000\n",
    "        y_max = 0\n",
    "        margin_x = 240\n",
    "        margin_y = 190\n",
    "        if not results.pose_landmarks:\n",
    "            continue\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            x_min = min(x_min, landmark.x)\n",
    "            x_max = max(x_max, landmark.x)\n",
    "            y_min = min(y_min, landmark.y)\n",
    "            y_max = max(y_max, landmark.y)\n",
    "\n",
    "        x_min = int(x_min * image.shape[1])\n",
    "        x_max = int(x_max * image.shape[1])\n",
    "        y_min = int(y_min * image.shape[0])\n",
    "        y_max = int(y_max * image.shape[0])\n",
    "\n",
    "        x_min = max(0,x_min - margin_x)\n",
    "        y_min = max(0,y_min - margin_y)\n",
    "        x_max = min(image.shape[1],x_max + margin_x)\n",
    "        y_max = min(image.shape[0],y_max + margin_y)\n",
    "\n",
    "        rs = results.pose_landmarks.landmark[12]\n",
    "        rs = rs.x*image.shape[1]\n",
    "        print(rs)\n",
    "\n",
    "        bbox = np.array([x_min, y_min, x_max, y_max])\n",
    "        xywh = np.array([x_min, y_min, x_max - x_min, y_max - y_min])\n",
    "\n",
    "\n",
    "        predictor.set_image(image)\n",
    "\n",
    "        mask, _, _ = predictor.predict(\n",
    "          point_coords=None,\n",
    "          point_labels=None,\n",
    "          box=bbox,\n",
    "          multimask_output=False,\n",
    "        )\n",
    "\n",
    "        mask = np.array(mask)\n",
    "        mask = np.where(mask, 1, 0)\n",
    "        # mask = np.expand_dims(mask, axis=0)\n",
    "        # mask = mask.astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(\"masks\", file), mask[0] * 255)\n",
    "\n",
    "        contours, _ = cv2.findContours(mask[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # Your call to find the contours\n",
    "        # threshold input image using otsu thresholding as mask and refine with morphology\n",
    "        ret, pngmask = cv2.threshold(mask[0].astype(np.uint8), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        kernel = np.ones((9,9), np.uint8)\n",
    "        pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_CLOSE, kernel)\n",
    "        pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        result = image.copy()\n",
    "        result.flags.writeable = True\n",
    "        result = cv2.rectangle(result, (x_min,y_min), (x_max,y_max), (255, 0, 0), 2)\n",
    "\n",
    "        # contours, _ = cv2.findContours(mask[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        # print(contours[0])\n",
    "        mp_drawing.draw_landmarks(\n",
    "            result,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "        result[:, :, 3] = pngmask\n",
    "\n",
    "\n",
    "        cv2.imwrite(os.path.join(results_dir, file), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_centroid(contour):\n",
    "        \"\"\"Get the centroid of a contour.\"\"\"\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] != 0:\n",
    "            vertical_coordinate = int(M['m01'] / M['m00'])\n",
    "            horizontal_coordinate = int(M['m10'] / M['m00'])\n",
    "        else:\n",
    "            # if the contour has an area of 0, the centroid cannot be computed this way\n",
    "            # we use the mean of the contour points instead\n",
    "            vertical_coordinate, horizontal_coordinate = np.mean(contour, axis=0)[0]\n",
    "        return int(vertical_coordinate), int(horizontal_coordinate)\n",
    "\n",
    "def get_largest_contour(image):\n",
    "        \"\"\"Get the largest contour in an image.\"\"\"\n",
    "        image = cv2.imread(os.path.join(images_dir, image))\n",
    "        copy = image.copy()\n",
    "\n",
    "        #laplacian = cv2.Laplacian(image, cv2.CV_8U, ksize=3)\n",
    "        blur = cv2.GaussianBlur(image, (0, 0), 2)\n",
    "        gray = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "\n",
    "        ret, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "        closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15)))\n",
    "\n",
    "        contours, _ = cv2.findContours(closing, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "        largest_contour = contours[0]\n",
    "        cv2.drawContours(copy,largest_contour,-1,(0,0,255),4,cv2.LINE_AA)\n",
    "\n",
    "        vtc, hzt = get_contour_centroid(largest_contour)\n",
    "        copy = cv2.line(copy, (vtc-50,hzt), (vtc+50,hzt), color=(250, 250, 0), thickness=3)\n",
    "        copy = cv2.line(copy, (vtc,hzt-50), (vtc,hzt+50), color=(250, 250, 0), thickness=3)\n",
    "        cv2.imwrite(os.path.join(\"tests\", file), copy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "get_largest_contour(images[6])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

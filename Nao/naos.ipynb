{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ale-Coeto/vision/blob/main/naos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp4XwZvia1Fo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = \"raw\"\n",
        "results_dir = \"output\"\n",
        "bgs = \"backgrounds\"\n",
        "dataset = \"dataset\"\n",
        "\n",
        "if not os.path.exists(images_dir):\n",
        "  os.makedirs(images_dir)\n",
        "\n",
        "if not os.path.exists(results_dir):\n",
        "  os.makedirs(results_dir)\n",
        "\n",
        "if not os.path.exists(\"masks\"):\n",
        "  os.makedirs(\"masks\")\n",
        "\n",
        "if not os.path.exists(bgs):\n",
        "  os.makedirs(bgs)\n",
        "\n",
        "if not os.path.exists(\"dataset\"):\n",
        "  os.makedirs(\"dataset\")\n",
        "\n",
        "imgs_num = 37\n",
        "\n"
      ],
      "metadata": {
        "id": "5hJJzpYWbGnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segment_anything"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK1TszaBcBKK",
        "outputId": "a966b037-b252-4608-9636-66543f03596d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segment_anything\n",
            "  Downloading segment_anything-1.0-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: segment_anything\n",
            "Successfully installed segment_anything-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from segment_anything import sam_model_registry, SamPredictor"
      ],
      "metadata": {
        "id": "ppDZJANnbiqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sam_model = \"h\""
      ],
      "metadata": {
        "id": "w0ckv38XcGpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if sam_model ==\"h\":\n",
        "  sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "  model_type = \"vit_h\"\n",
        "else:\n",
        "  sam_checkpoint = \"sam_vit_l_0b3195.pth\"\n",
        "  model_type = \"vit_l\""
      ],
      "metadata": {
        "id": "8MGBwBL2cYUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ],
      "metadata": {
        "id": "8V0d3nvqcbT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "tbglZHmfccU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "HPhEpdBOcfQw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "8876930e-a6da-48f3-820e-25922abb28d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-befe9257fdfd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msam_model_registry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msam_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSamPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = [str(\"NAO\" + str(i) + \".jpeg\") for i in range(1, 38)] #38\n"
      ],
      "metadata": {
        "id": "5dx4LXnkclsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "xOzyoJgjoPTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp"
      ],
      "metadata": {
        "id": "7GPMpQ7UnfDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the pose solution from MediaPipe\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# Calling the solution for image drawing from MediaPipe\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles"
      ],
      "metadata": {
        "id": "kU4aTtwTnaPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMUaJoLaoqOZ",
        "outputId": "3594df24-4693-48ff-cad4-4be8365fd71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "masks  output  raw  sample_data  sam_vit_h_4b8939.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 1\n",
        "with mp_pose.Pose(\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5) as pose:\n",
        "    for file in images:\n",
        "        print(file)\n",
        "        image = cv2.imread(os.path.join(images_dir, file))\n",
        "        raw = image.copy()\n",
        "        results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        x_min = 10000\n",
        "        x_max = 0\n",
        "        y_min = 10000\n",
        "        y_max = 0\n",
        "        margin_x = 290\n",
        "        margin_y = 240\n",
        "        if not results.pose_landmarks:\n",
        "            continue\n",
        "        for landmark in results.pose_landmarks.landmark:\n",
        "            x_min = min(x_min, landmark.x)\n",
        "            x_max = max(x_max, landmark.x)\n",
        "            y_min = min(y_min, landmark.y)\n",
        "            y_max = max(y_max, landmark.y)\n",
        "\n",
        "        x_min = int(x_min * image.shape[1])\n",
        "        x_max = int(x_max * image.shape[1])\n",
        "        y_min = int(y_min * image.shape[0])\n",
        "        y_max = int(y_max * image.shape[0])\n",
        "\n",
        "        x_min = max(0,x_min - margin_x)\n",
        "        y_min = max(0,y_min - margin_y)\n",
        "        x_max = min(image.shape[1],x_max + margin_x)\n",
        "        y_max = min(image.shape[0],y_max + margin_y)\n",
        "\n",
        "        bbox = np.array([x_min, y_min, x_max, y_max])\n",
        "        xywh = np.array([x_min, y_min, x_max - x_min, y_max - y_min])\n",
        "\n",
        "        predictor.set_image(image)\n",
        "\n",
        "        mask, _, _ = predictor.predict(\n",
        "          point_coords=None,\n",
        "          point_labels=None,\n",
        "          box=bbox,\n",
        "          multimask_output=False,\n",
        "        )\n",
        "\n",
        "\n",
        "        contours, _ = cv2.findContours(mask[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # Your call to find the contours\n",
        "        # threshold input image using otsu thresholding as mask and refine with morphology\n",
        "        ret, pngmask = cv2.threshold(mask[0].astype(np.uint8), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "        kernel = np.ones((9,9), np.uint8)\n",
        "        pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_CLOSE, kernel)\n",
        "        pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "        # put mask into alpha channel of result\n",
        "        result = image.copy()\n",
        "        result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
        "        result[:, :, 3] = pngmask\n",
        "\n",
        "        #crop img\n",
        "        x,y,w,h = cv2.boundingRect(contours[0])\n",
        "        result = result[y:y+h, x:x+w]\n",
        "\n",
        "        cv2.imwrite(f\"{results_dir}/NAO{i}.png\",result)\n",
        "        i=i+1\n",
        "\n",
        "        images=[]\n",
        "annotations=[]\n",
        "annotations2=[]\n",
        "\n",
        "img_id=1\n",
        "anno_id=int(0)\n",
        "\n",
        "rescaling_min = 0.2\n",
        "rescaling_max = 0.6\n",
        "\n",
        "# Ratios at which these values will be modified\n",
        "brightness_ratio = 0.05\n",
        "saturation_ratio = 0.05\n",
        "hue_ratio = 0.02\n",
        "\n",
        "for j in range(10):\n",
        "    #select hramdomly how many objects will be in an image\n",
        "    num_objects = random.randint(1, 3)\n",
        "    # print(\"number of objects\",num_objects)\n",
        "\n",
        "    # Select random foreground images from the three folders, with replacement\n",
        "    #fg_categories = random.choices(\"nao\", k=num_objects)\n",
        "\n",
        "    fg_files_selected = []\n",
        "    results_path = os.listdir(results_dir)\n",
        "    for i in (0,num_objects):\n",
        "        fg_files_selected.append(random.choice(results_path))\n",
        "    print(\"seleccion\",fg_files_selected)\n",
        "\n",
        "    # Load the selected foreground images using Pillow -- img[0] is image, img[1] is path\n",
        "    fg_imgs = []\n",
        "    images_dir = \"raw/\"\n",
        "    for img in fg_files_selected:\n",
        "        folder = \"output/\"\n",
        "        if img[0] == 'N':\n",
        "          fg_imgs.append([Image.open(folder + img),folder+img])\n",
        "\n",
        "    # Randomly resize and rotate the foreground images using Pillow's transform module\n",
        "    # img[0] is image, img[1] is path\n",
        "    for img in fg_imgs:\n",
        "        fg_img=img[0]\n",
        "        if (fg_img.height > 0 and fg_img.width > 0):\n",
        "          angle = random.randint(-5, 5)\n",
        "          scale = random.uniform(rescaling_min, rescaling_max)\n",
        "          fg_img = fg_img.rotate(angle, resample=Image.BICUBIC, expand=True)\n",
        "          fg_img = fg_img.resize((int(fg_img.width * scale), int(fg_img.height * scale)))\n",
        "          fg_img = ImageEnhance.Brightness(fg_img).enhance(random.uniform(1.0, 1.5))\n",
        "          fg_img = ImageEnhance.Contrast(fg_img).enhance(random.uniform(0.9, 1.1))\n",
        "          fg_img = ImageEnhance.Color(fg_img).enhance(random.uniform(0.7, 1.3))\n",
        "          fg_img = fg_img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.0, 0.5)))\n",
        "\n",
        "\n",
        "        img[0] = fg_img\n",
        "\n",
        "    # Load the background image using Pillow\n",
        "    bg_folder = \"backgrounds/\"\n",
        "    bg_files = os.listdir(bg_folder)\n",
        "    bg_file = random.choice(bg_files)\n",
        "    if bg_file[0] != \".\":\n",
        "      bg_img = Image.open(bg_folder + bg_file)\n",
        "\n",
        "      # Define the maximum overlap as a percentage\n",
        "    max_overlap_pct = 10\n",
        "\n",
        "    # Define an array to keep track of occupied areas\n",
        "    occupied = np.zeros((bg_img.height, bg_img.width))\n",
        "\n",
        "    print(fg_imgs)\n",
        "\n",
        "    for img in fg_imgs:\n",
        "        fg_img=img[0]\n",
        "\n",
        "        # Calculate the maximum overlap area\n",
        "        max_overlap_area = (fg_img.width * fg_img.height)\n",
        "\n",
        "        seg_img = img[0]\n",
        "        print(seg_img)\n",
        "\n",
        "        # Convert the image to a NumPy array\n",
        "        img_arr = np.array(seg_img)\n",
        "\n",
        "        # Create a binary mask of the non-transparent pixels\n",
        "        mask = img_arr[:, :, 3] != 0\n",
        "\n",
        "        # Convert the mask to a COCO format segmentation\n",
        "        segmentation = []\n",
        "        for i in range(mask.shape[0]):\n",
        "            for j in range(mask.shape[1]):\n",
        "                if mask[i, j]:\n",
        "                    segmentation.append(j)\n",
        "                    segmentation.append(i)\n",
        "        segmentation = [segmentation]\n",
        "\n",
        "        #Calculate the area of the segmentation\n",
        "        area = 0\n",
        "        for i in range(len(segmentation[0]) // 2):\n",
        "            x1 = segmentation[0][2 * i]\n",
        "            y1 = segmentation[0][2 * i + 1]\n",
        "            x2 = segmentation[0][(2 * i + 2) % len(segmentation[0])]\n",
        "            y2 = segmentation[0][(2 * i + 3) % len(segmentation[0])]\n",
        "            area += x1 * y2 - x2 * y1\n",
        "        area = abs(area) / 2\n",
        "\n",
        "\n",
        "        # Calculate the maximum allowed position for the top-left corner\n",
        "        max_x = bg_img.width - fg_img.width\n",
        "        max_y = bg_img.height - fg_img.height\n",
        "        area = fg_img.width * fg_img.height\n",
        "\n",
        "        # Generate a random location until an unoccupied area is found that meets the overlap limit\n",
        "        total_area = bg_img.width * bg_img.height\n",
        "        overlap_area = total_area\n",
        "\n",
        "        while overlap_area / area > max_overlap_pct / 100:\n",
        "            x = random.randint(0, max_x)\n",
        "            y = random.randint(0, max_y)\n",
        "\n",
        "            # Calculate the overlap area\n",
        "            overlap_area = np.sum(occupied[y:y+fg_img.height, x:x+fg_img.width])\n",
        "\n",
        "            # Check if the area is unoccupied and the overlap limit is not exceeded\n",
        "            if (max_overlap_area) >= overlap_area/10:\n",
        "                break\n",
        "            if i==10:\n",
        "                continue\n",
        "\n",
        "        for i in range(0, len(segmentation[0])):\n",
        "            if i % 2:\n",
        "                segmentation[0][i]=int(segmentation[0][i]+y)\n",
        "            else :\n",
        "                segmentation[0][i]=int(segmentation[0][i]+x)\n",
        "        # Update the occupied array\n",
        "        occupied[y:y+fg_img.height, x:x+fg_img.width] = 1\n",
        "        bg_img.paste(fg_img, (x, y), fg_img)\n",
        "        annotations.append({\"id\": anno_id,\"image_id\": img_id,\"category_id\": 1,\"bbox\": [x, y, fg_img.width, fg_img.height],\"segmentation\": [],\"area\": fg_img.height*fg_img.width,\"iscrowd\": 0})\n",
        "        anno_id=anno_id+1\n",
        "\n",
        "    # copy = np.array(bg_img)\n",
        "    # cv2.imwrite(os.path.join(dataset, file), copy)\n",
        "\n",
        "    bg_img.save(\"dataset/\"+str(img_id)+\".jpg\", quality=100)\n",
        "    images.append({\"id\": img_id, \"file_name\": str(img_id)+\".jpg\",\"height\": bg_img.height,\"width\": bg_img.width})\n",
        "    img_id=img_id+1\n"
      ],
      "metadata": {
        "id": "suxouzY_aJHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#results_dir\n",
        "#dataset\n",
        "#bgs\n",
        "\n",
        "fg_files = os.listdir(results_dir)"
      ],
      "metadata": {
        "id": "oc6yW80p4QtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LajF86dANHxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10f22aad-f6a8-4564-acc1-092f7e27842d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seleccion ['NAO14.png', 'NAO9.png']\n",
            "[[<PIL.Image.Image image mode=RGBA size=437x767 at 0x7B56B87E3CA0>, 'output/NAO14.png'], [<PIL.Image.Image image mode=RGBA size=1x1 at 0x7B56B87E0FD0>, 'output/NAO9.png']]\n",
            "<PIL.Image.Image image mode=RGBA size=437x767 at 0x7B56B87E3CA0>\n",
            "<PIL.Image.Image image mode=RGBA size=1x1 at 0x7B56B87E0FD0>\n",
            "seleccion ['NAO1.png', 'NAO10.png']\n",
            "[[<PIL.Image.Image image mode=RGBA size=1128x1556 at 0x7B56B87E18D0>, 'output/NAO1.png'], [<PIL.Image.Image image mode=RGBA size=2x2 at 0x7B56B87E21D0>, 'output/NAO10.png']]\n",
            "<PIL.Image.Image image mode=RGBA size=1128x1556 at 0x7B56B87E18D0>\n",
            "<PIL.Image.Image image mode=RGBA size=2x2 at 0x7B56B87E21D0>\n",
            "seleccion ['NAO9.png', 'NAO10.png']\n",
            "[[<PIL.Image.Image image mode=RGBA size=1x1 at 0x7B56B87E25C0>, 'output/NAO9.png'], [<PIL.Image.Image image mode=RGBA size=4x4 at 0x7B56B87E2F20>, 'output/NAO10.png']]\n",
            "<PIL.Image.Image image mode=RGBA size=1x1 at 0x7B56B87E25C0>\n",
            "<PIL.Image.Image image mode=RGBA size=4x4 at 0x7B56B87E2F20>\n",
            "seleccion ['NAO2.png', '.ipynb_checkpoints']\n",
            "[[<PIL.Image.Image image mode=RGBA size=1047x1475 at 0x7B56B87E3C70>, 'output/NAO2.png']]\n",
            "<PIL.Image.Image image mode=RGBA size=1047x1475 at 0x7B56B87E3C70>\n",
            "seleccion ['NAO11.png', 'NAO1.png']\n",
            "[[<PIL.Image.Image image mode=RGBA size=776x756 at 0x7B56B87E2980>, 'output/NAO11.png'], [<PIL.Image.Image image mode=RGBA size=960x1324 at 0x7B56B87E11E0>, 'output/NAO1.png']]\n",
            "<PIL.Image.Image image mode=RGBA size=776x756 at 0x7B56B87E2980>\n",
            "<PIL.Image.Image image mode=RGBA size=960x1324 at 0x7B56B87E11E0>\n",
            "seleccion ['NAO4.png', 'NAO6.png']\n",
            "[[<PIL.Image.Image image mode=RGBA size=5x5 at 0x7B56B87E3C40>, 'output/NAO4.png'], [<PIL.Image.Image image mode=RGBA size=642x903 at 0x7B56B87E3E80>, 'output/NAO6.png']]\n",
            "<PIL.Image.Image image mode=RGBA size=5x5 at 0x7B56B87E3C40>\n",
            "<PIL.Image.Image image mode=RGBA size=642x903 at 0x7B56B87E3E80>\n",
            "seleccion ['NAO1.png', 'NAO9.png']\n",
            "[[<PIL.Image.Image image mode=RGBA size=1069x1492 at 0x7B56B87E2980>, 'output/NAO1.png'], [<PIL.Image.Image image mode=RGBA size=4x2 at 0x7B56B87E0F10>, 'output/NAO9.png']]\n",
            "<PIL.Image.Image image mode=RGBA size=1069x1492 at 0x7B56B87E2980>\n",
            "<PIL.Image.Image image mode=RGBA size=4x2 at 0x7B56B87E0F10>\n",
            "seleccion ['NAO6.png', 'NAO4.png']\n",
            "[[<PIL.Image.Image image mode=RGBA size=994x1397 at 0x7B56B87E3AF0>, 'output/NAO6.png'], [<PIL.Image.Image image mode=RGBA size=2x3 at 0x7B56B87E2DA0>, 'output/NAO4.png']]\n",
            "<PIL.Image.Image image mode=RGBA size=994x1397 at 0x7B56B87E3AF0>\n",
            "<PIL.Image.Image image mode=RGBA size=2x3 at 0x7B56B87E2DA0>\n",
            "seleccion ['NAO3.png', 'NAO9.png']\n",
            "[[<PIL.Image.Image image mode=RGBA size=992x1522 at 0x7B56B87E1090>, 'output/NAO3.png'], [<PIL.Image.Image image mode=RGBA size=2x1 at 0x7B56B87E1840>, 'output/NAO9.png']]\n",
            "<PIL.Image.Image image mode=RGBA size=992x1522 at 0x7B56B87E1090>\n",
            "<PIL.Image.Image image mode=RGBA size=2x1 at 0x7B56B87E1840>\n",
            "seleccion ['NAO14.png', '.ipynb_checkpoints']\n",
            "[[<PIL.Image.Image image mode=RGBA size=705x1238 at 0x7B56B87E3820>, 'output/NAO14.png']]\n",
            "<PIL.Image.Image image mode=RGBA size=705x1238 at 0x7B56B87E3820>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random\n",
        "import json\n",
        "from PIL import Image, ImageDraw, ImageEnhance, ImageFilter\n",
        "from pycocotools import mask\n",
        "from skimage import measure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yh1NO1YflZg",
        "outputId": "67f61c0d-88bc-4aa5-84db-655a2d080dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[<PIL.Image.Image image mode=RGBA size=4x2 at 0x7B56F1174880>, 'output/NAO15.png'], [<PIL.Image.Image image mode=RGBA size=354x486 at 0x7B56F11772E0>, 'output/NAO6.png']]\n",
            "<PIL.Image.Image image mode=RGBA size=4x2 at 0x7B56F1174880>\n",
            "<PIL.Image.Image image mode=RGBA size=354x486 at 0x7B56F11772E0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the COCO dictionary\n",
        "coco_dict = {\n",
        "    \"images\": images,\n",
        "    \"annotations\": annotations,\n",
        "    \"categories\": \"NAO\"\n",
        "}"
      ],
      "metadata": {
        "id": "at7e8EB__ZeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coco_dict\n",
        "# Convert the dictionary to a JSON string\n",
        "json_string = json.dumps(coco_dict)\n",
        "\n",
        "# Write the JSON string to a file\n",
        "with open(\"annotations_val.json\", 'w') as f:\n",
        "    f.write(json_string)"
      ],
      "metadata": {
        "id": "yzKc5f9B_aQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MY_KEY = \"OHK7KhOXnobE9SiVDQhi\"\n",
        "\n",
        "for filename in os.listdir(dataset):\n",
        "  if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "      print(filename)\n",
        "\n",
        "      # Load Image with PIL\n",
        "      image = Image.open(filename).convert(\"RGB\")\n",
        "\n",
        "      # Convert to JPEG Buffer\n",
        "      buffered = io.BytesIO()\n",
        "      image.save(buffered, quality=90, format=\"JPEG\")\n",
        "\n",
        "      # Base 64 Encode\n",
        "      img_str = base64.b64encode(buffered.getvalue())\n",
        "      img_str = img_str.decode(\"ascii\")\n",
        "\n",
        "      # Construct the URL\n",
        "      upload_url = \"\".join([\n",
        "          \"https://app.roboflow.com/roborregos/test-vkojw/upload\",\n",
        "          \"?api_key=\" + MY_KEY,\n",
        "          \"&name=\" +str(filename),\n",
        "          \"&split=train\"\n",
        "      ])\n",
        "\n",
        "      # POST to the API\n",
        "      r = requests.post(upload_url, data=img_str, headers={\n",
        "          \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
        "      })\n",
        "\n",
        "      # Output result\n",
        "      print(r.json())"
      ],
      "metadata": {
        "id": "yULYEi5vWKz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "JsICvMDQnb_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from ultralytics.data.converter import convert_coco\n",
        "\n",
        "# newFile = convert_coco(labels_dir='annotations.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddNKEGSJIg4j",
        "outputId": "1079fc83-0d19-4e2e-e7ef-09dfd9aaeb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    }
  ]
}